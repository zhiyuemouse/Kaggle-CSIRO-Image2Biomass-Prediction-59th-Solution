{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a8015b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/hjs/anaconda3/envs/transformers/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f2f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    is_debug = False\n",
    "    seed = 308\n",
    "    n_folds = 5\n",
    "\n",
    "    test_csv = \"CSIRO/CSIRO_my_5fold_train_csv.csv\"\n",
    "    test_img_path = \"CSIRO/train\" # (1000, 2000)\n",
    "    n_workers = os.cpu_count() // 2\n",
    "\n",
    "    test_batch_size = 16\n",
    "\n",
    "    model_path = \"CSIRO/output/2025-12-27_00:55:16_vit_base_patch16_dinov3.lvd1689m_output\"\n",
    "    model_name = \"vit_base_patch16_dinov3.lvd1689m\"\n",
    "    if \"dinov2\" in model_name:\n",
    "        img_size = [518, 1036]\n",
    "    elif \"eva02\" in model_name:\n",
    "        img_size = [448, 896]\n",
    "    else:\n",
    "        img_size = [512, 1024]\n",
    "    \"\"\"\n",
    "    tf_efficientnet_b0.ns_jft_in1k\n",
    "    edgenext_base.in21k_ft_in1k\n",
    "    convnextv2_tiny.fcmae_ft_in22k_in1k\n",
    "    vit_base_patch14_dinov2.lvd142m\n",
    "    vit_base_patch16_dinov3.lvd1689m\n",
    "    \"\"\"\n",
    "\n",
    "    head_out = 5\n",
    "    DataParallel = False\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b949929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=308):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "set_seed(CONFIG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6de77d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID1011485656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID1012260530</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID1025234388</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID1028611175</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID1035947949</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>ID975115267</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>ID978026131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>ID980538882</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>ID980878870</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>ID983582017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sample_id  fold\n",
       "0    ID1011485656     0\n",
       "1    ID1012260530     1\n",
       "2    ID1025234388     2\n",
       "3    ID1028611175     3\n",
       "4    ID1035947949     4\n",
       "..            ...   ...\n",
       "352   ID975115267     3\n",
       "353   ID978026131     0\n",
       "354   ID980538882     4\n",
       "355   ID980878870     2\n",
       "356   ID983582017     2\n",
       "\n",
       "[357 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all = pd.read_csv(CONFIG.test_csv)\n",
    "id_and_fold = {}\n",
    "for i in range(len(test_all)):\n",
    "    row = test_all.iloc[i, :]\n",
    "    _id = row.sample_id.split(\"_\")[0]\n",
    "    _fold = row.fold.item()\n",
    "    if _id not in id_and_fold.keys():\n",
    "        id_and_fold[_id] = _fold\n",
    "\n",
    "test = pd.DataFrame(list(id_and_fold.items()), columns=['sample_id', 'fold'])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e08460bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集得分: 0.99926\n",
      "score: -0.57594\n"
     ]
    }
   ],
   "source": [
    "def Calculate_Weighted_R2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算 Kaggle CSIRO Image2Biomass 比赛的加权 R2 分数。\n",
    "    \n",
    "    参数:\n",
    "    y_true: 真实值，形状为 [n_samples, 5]\n",
    "    y_pred: 预测值，形状为 [n_samples, 5]\n",
    "    \n",
    "    列顺序假设:\n",
    "    0: Dry_Clover_g (w=0.1)\n",
    "    1: Dry_Dead_g   (w=0.1)\n",
    "    2: Dry_Green_g  (w=0.1)\n",
    "    3: Dry_Total_g  (w=0.5)\n",
    "    4: GDM_g        (w=0.2)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 定义权重向量\n",
    "    weights = np.array([0.1, 0.1, 0.1, 0.5, 0.2])\n",
    "    \n",
    "    # 2. 确保输入是 numpy 数组\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # 3. 计算全局加权均值 (Global Weighted Mean)\n",
    "    # 这里的 sum(weights) = 1.0，所以分母实际上就是 样本数 * 1.0\n",
    "    # 我们利用广播机制将权重应用到每一行\n",
    "    weighted_sum = np.sum(y_true * weights) \n",
    "    total_weight = np.sum(weights) * y_true.shape[0] # weights总和 * 样本数\n",
    "    y_bar_w = weighted_sum / total_weight\n",
    "    \n",
    "    # 4. 计算残差平方和 (SS_res)\n",
    "    # 公式: sum( w_j * (y_j - y_hat_j)^2 )\n",
    "    ss_res = np.sum(weights * (y_true - y_pred)**2)\n",
    "    \n",
    "    # 5. 计算总离差平方和 (SS_tot)\n",
    "    # 公式: sum( w_j * (y_j - y_bar_w)^2 )\n",
    "    # 注意这里减去的是全局加权均值 y_bar_w\n",
    "    ss_tot = np.sum(weights * (y_true - y_bar_w)**2)\n",
    "    \n",
    "    # 6. 计算 R2\n",
    "    # 避免分母为0的极个别情况\n",
    "    if ss_tot == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    return r2\n",
    "\n",
    "# --- 测试用例 ---\n",
    "# 模拟数据\n",
    "dummy_true = np.array([\n",
    "    [5, 16, 36, 54, 42],\n",
    "    [3, 8, 10, 18, 13]\n",
    "])\n",
    "# 假设预测非常接近\n",
    "dummy_pred = dummy_true + 0.5 \n",
    "\n",
    "score = Calculate_Weighted_R2(dummy_true, dummy_pred)\n",
    "print(f\"验证集得分: {score:.5f}\")\n",
    "\n",
    "# 使用示例\n",
    "# 模拟验证集数据\n",
    "n_valid_samples = 16\n",
    "# 随机生成验证集真实值和预测值\n",
    "y_valid_true = np.random.rand(n_valid_samples, 5)\n",
    "y_valid_pred = np.random.rand(n_valid_samples, 5)\n",
    "# 计算分数\n",
    "score = Calculate_Weighted_R2(y_valid_true, y_valid_pred).item()\n",
    "print(f\"score: {score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7989b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型: vit_base_patch16_dinov3.lvd1689m\n",
      "自动获取 Mean: (0.485, 0.456, 0.406)\n",
      "自动获取 Std:  (0.229, 0.224, 0.225)\n"
     ]
    }
   ],
   "source": [
    "# 1. 获取配置对象\n",
    "cfg = timm.get_pretrained_cfg(CONFIG.model_name)\n",
    "\n",
    "# 2. 【核心修复】先转成字典 (.to_dict()) 再传入\n",
    "# 这样 resolve_data_config 就能正常使用 .get() 方法了\n",
    "cfg_dict = cfg.to_dict()\n",
    "data_config = timm.data.resolve_data_config(pretrained_cfg=cfg_dict)\n",
    "\n",
    "# 3. 提取结果\n",
    "_mean = data_config['mean']\n",
    "_std = data_config['std']\n",
    "\n",
    "print(f\"模型: {CONFIG.model_name}\")\n",
    "print(f\"自动获取 Mean: {_mean}\")\n",
    "print(f\"自动获取 Std:  {_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fe0b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(img):\n",
    "    composition = A.Compose([\n",
    "        A.Resize(CONFIG.img_size[0], CONFIG.img_size[1]),\n",
    "        A.Normalize(\n",
    "            mean=_mean,\n",
    "            std=_std\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    return composition(image=img)[\"image\"]\n",
    "\n",
    "class CSIRODataset(Dataset):\n",
    "    def __init__(self, df, original_train=test_all, transform=transform):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.original_train = original_train\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx, :]\n",
    "        img_id = row.sample_id\n",
    "\n",
    "        img_path = os.path.join(CONFIG.test_img_path, img_id + \".jpg\")\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        img = np.array(img)\n",
    "        if self.transform != None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        target_id = [\"__Dry_Clover_g\", \"__Dry_Dead_g\", \"__Dry_Green_g\", \"__Dry_Total_g\", \"__GDM_g\"]\n",
    "        label = []\n",
    "        for _id in target_id:\n",
    "            tmp_row = self.original_train[self.original_train[\"sample_id\"] == f\"{img_id}{_id}\"][\"target\"].item()\n",
    "            label.append(tmp_row)\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "def prepare_loaders(df, fold=0):\n",
    "    df_test = df[df[\"fold\"] == fold]\n",
    "    \n",
    "    test_datasets = CSIRODataset(df=df_test, transform=transform)\n",
    "    \n",
    "    test_loader = DataLoader(test_datasets, batch_size=CONFIG.test_batch_size, num_workers=CONFIG.n_workers, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76cf5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSIROModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CSIROModel, self).__init__()\n",
    "        self.backbone = timm.create_model(model_name=CONFIG.model_name, \n",
    "                                          pretrained=False)\n",
    "\n",
    "        if \"efficientnet\" in CONFIG.model_name:\n",
    "            in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        elif \"edgenext\" in CONFIG.model_name:\n",
    "            in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "        elif \"convnext\" in CONFIG.model_name:\n",
    "            if \"dino\" in CONFIG.model_name:\n",
    "                if \"tiny\" in CONFIG.model_name:\n",
    "                    in_features = 768\n",
    "                elif \"base\" in CONFIG.model_name:\n",
    "                    in_features = 1024\n",
    "            else:\n",
    "                in_features = self.backbone.head.fc.in_features\n",
    "                self.backbone.head.fc = nn.Identity()\n",
    "        elif \"vit\" in CONFIG.model_name:\n",
    "            if \"dino\" in CONFIG.model_name:\n",
    "                in_features = 1536\n",
    "            else:\n",
    "                in_features = self.backbone.head.fc.in_features * 2\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "        elif \"eva02\" in CONFIG.model_name:\n",
    "            in_features = self.backbone.head.in_features * 2\n",
    "            self.backbone.head = nn.Identity()\n",
    "        else:\n",
    "            raise(\"Error model!\")\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features // 2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features // 2, CONFIG.head_out),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        if \"vit\" in CONFIG.model_name or \"eva02\" in CONFIG.model_name:\n",
    "            mid = CONFIG.img_size[0]\n",
    "            x_left = x[:, :, :, :mid]\n",
    "            x_right = x[:, :, :, mid:]\n",
    "            _tmp1 = self.backbone(x_left)\n",
    "            _tmp2 = self.backbone(x_right)\n",
    "            _tmp = torch.cat([_tmp1, _tmp2], dim=1) # shape: [B, 1536]\n",
    "        else:\n",
    "            _tmp = self.backbone(x)\n",
    "        output = self.head(_tmp)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81a12294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 best path : 1_CV_0.8875_Loss70.0591_epoch20.pth\n",
      "Fold 2 best path : 2_CV_0.8195_Loss159.2138_epoch12.pth\n",
      "Fold 3 best path : 3_CV_0.7754_Loss175.1131_epoch27.pth\n",
      "Fold 4 best path : 4_CV_0.8683_Loss121.2981_epoch22.pth\n",
      "Fold 5 best path : 5_CV_0.8117_Loss149.2619_epoch22.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1_CV_0.8875_Loss70.0591_epoch20.pth',\n",
       " '2_CV_0.8195_Loss159.2138_epoch12.pth',\n",
       " '3_CV_0.7754_Loss175.1131_epoch27.pth',\n",
       " '4_CV_0.8683_Loss121.2981_epoch22.pth',\n",
       " '5_CV_0.8117_Loss149.2619_epoch22.pth']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paths = os.listdir(CONFIG.model_path)\n",
    "all_paths\n",
    "paths = []\n",
    "\n",
    "for i in range(CONFIG.n_folds):\n",
    "    _tmp_paths = []\n",
    "    for _tmp_path in all_paths:\n",
    "        if _tmp_path.split(\"_\")[0] == str(i+1):\n",
    "            _tmp_paths.append(_tmp_path)\n",
    "    best_fold_path = sorted(_tmp_paths, key=lambda x:float(x.split(\"_\")[2]))[-1]\n",
    "    print(f\"Fold {i+1} best path : {best_fold_path}\")\n",
    "    paths.append(best_fold_path)\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18e60f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold_1_CV_0.8875_Loss70.0591_epoch20.pth Load Success!\n",
      "Fold_2_CV_0.8195_Loss159.2138_epoch12.pth Load Success!\n",
      "Fold_3_CV_0.7754_Loss175.1131_epoch27.pth Load Success!\n",
      "Fold_4_CV_0.8683_Loss121.2981_epoch22.pth Load Success!\n",
      "Fold_5_CV_0.8117_Loss149.2619_epoch22.pth Load Success!\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "if CONFIG.DataParallel:\n",
    "    device_ids = [0, 1]\n",
    "    for i in range(CONFIG.n_folds):\n",
    "        model = CSIROModel()\n",
    "        model = torch.nn.DataParallel(model, device_ids=device_ids)\n",
    "        model = model.cuda()\n",
    "        model.load_state_dict(torch.load(os.path.join(CONFIG.model_path, paths[i])))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "        print(f\"Fold_{paths[i]} Load Success!\")\n",
    "else:\n",
    "    for i in range(CONFIG.n_folds):\n",
    "        model = CSIROModel()\n",
    "        model = model.to(CONFIG.device)\n",
    "        model.load_state_dict(torch.load(os.path.join(CONFIG.model_path, paths[i])))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "        print(f\"Fold_{paths[i]} Load Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "254d0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Infer(model, test_loader):\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    bar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    with torch.no_grad():\n",
    "        for step, (images, labels) in bar:\n",
    "            batch_size = images.size(0)\n",
    "            if CONFIG.DataParallel:\n",
    "                images = images.cuda().float()\n",
    "                labels = labels.cuda().float()\n",
    "            else:\n",
    "                images = images.to(CONFIG.device, dtype=torch.float)\n",
    "                labels = labels.to(CONFIG.device, dtype=torch.float)\n",
    "                \n",
    "            output = model(images)\n",
    "            y_preds.append(output.detach().cpu().numpy())\n",
    "            y_trues.append(labels.detach().cpu().numpy())\n",
    "            \n",
    "    y_preds = np.concatenate(y_preds)\n",
    "    y_trues = np.concatenate(y_trues)\n",
    "    return y_preds, y_trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d469b3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== infer on Fold 1 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:08<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== infer on Fold 2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== infer on Fold 3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== infer on Fold 4 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== infer on Fold 5 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:02<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "y_preds = []\n",
    "y_trues = []\n",
    "for fold in range(0, CONFIG.n_folds):\n",
    "    print(f\"==================== infer on Fold {fold+1} ====================\")\n",
    "    \n",
    "    test_loader = prepare_loaders(test, fold)\n",
    "    y_pred, y_true = Infer(models[fold], test_loader)\n",
    "    y_preds.append(y_pred)\n",
    "    y_trues.append(y_true)\n",
    "\n",
    "oof = np.concatenate(y_preds)\n",
    "true = np.concatenate(y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88403ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local CV :  0.9579038769353937\n"
     ]
    }
   ],
   "source": [
    "local_cv = Calculate_Weighted_R2(true, oof)\n",
    "print(\"Local CV : \", local_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c95a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
